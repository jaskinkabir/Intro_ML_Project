{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'smoke_detection_iot.csv'\n",
    "\n",
    "data = pd.read_csv(path).drop(['Unnamed: 0', 'UTC', 'CNT'], axis=1)\n",
    "Y_df = data['Fire Alarm']\n",
    "X_df = data.drop('Fire Alarm', axis=1)\n",
    "\n",
    "Y_test_5f = X_df.values\n",
    "Y_pred = Y_df.values\n",
    "\n",
    "X_train_raw, X_test_raw, Y_train_5f, Y_test_5f = train_test_split(Y_test_5f, Y_pred, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_raw = scaler.fit_transform(X_train_raw)\n",
    "X_test_raw = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6690529584884644\n",
      "Epoch 500 Loss: 0.003392779966816306\n",
      "Epoch 1000 Loss: 0.0006458048592321575\n",
      "Epoch 1500 Loss: 0.00026241334853693843\n",
      "Epoch 2000 Loss: 0.00015851714124437422\n",
      "Epoch 2500 Loss: 0.00010259856207994744\n",
      "Accuracy: 0.9995209963276385\n",
      "Precision: 0.9995517202734506\n",
      "Recall: 0.9997758098867839\n",
      "F1: 0.9996637525218561\n",
      "Confusion_matrix:\n",
      "[[3601    4]\n",
      " [   2 8919]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from alarmnetclass import AlarmNet\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "alpha = 1e-2\n",
    "epochs = 3000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = AlarmNet(\n",
    "    num_features=X_train_raw.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_raw_device = torch.tensor(X_train_raw).float().to(device)\n",
    "X_test_raw_device = torch.tensor(X_test_raw).float().to(device)\n",
    "Y_train_raw_device = torch.tensor(Y_train_5f).float().view(-1, 1).to(device)\n",
    "Y_test_raw_device = torch.tensor(Y_test_5f).float().view(-1, 1).to(device)\n",
    "model.train(epochs, X_train_raw_device, X_test_raw_device, Y_train_raw_device, Y_test_raw_device, alpha)\n",
    "model.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "- Initially there are 15 features\n",
    "- 3 are unusable\n",
    "    - UTC Timestamp\n",
    "    - CNT\n",
    "    - Unnamed: 0\n",
    "- 12 features are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humidity[%]       0.399846\n",
      "Raw Ethanol       0.340652\n",
      "Pressure[hPa]     0.249797\n",
      "TVOC[ppb]         0.214743\n",
      "Temperature[C]    0.163902\n",
      "NC0.5             0.128118\n",
      "PM1.0             0.110552\n",
      "Raw H2            0.107007\n",
      "eCO2[ppm]         0.097006\n",
      "PM2.5             0.084916\n",
      "NC1.0             0.082828\n",
      "NC2.5             0.057707\n",
      "Name: Fire Alarm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "corr = np.abs(data.corr())\n",
    "ranking = corr['Fire Alarm'].sort_values(ascending=False)[1:]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: Index(['Humidity[%]', 'Raw Ethanol', 'Pressure[hPa]', 'TVOC[ppb]'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_drops = 8\n",
    "remaining_features = ranking.index[:-num_drops]\n",
    "\n",
    "\n",
    "X_df_dropped = data[remaining_features]\n",
    "print('Remaining features:', X_df_dropped.columns)\n",
    "X_train_dropped, X_test_dropped, Y_train_dropped, Y_test_dropped = train_test_split(X_df_dropped.values, Y_pred, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.transform(X_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7509467601776123\n",
      "Epoch 500 Loss: 0.015842126682400703\n",
      "Epoch 1000 Loss: 0.06398574262857437\n",
      "Epoch 1500 Loss: 0.050980836153030396\n",
      "Epoch 2000 Loss: 0.04781293869018555\n",
      "Epoch 2500 Loss: 0.046131569892168045\n",
      "Accuracy: 0.999041992655277\n",
      "Precision: 0.9987683350128765\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9993278064082456\n",
      "Confusion_matrix:\n",
      "[[3594   11]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_model = AlarmNet(\n",
    "    num_features=X_train_dropped.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_dropped_device = torch.tensor(X_train_dropped).float().to(device)\n",
    "X_test_dropped_device = torch.tensor(X_test_dropped).float().to(device)\n",
    "Y_train_dropped_device = torch.tensor(Y_train_dropped).float().view(-1, 1).to(device)\n",
    "Y_test_dropped_device = torch.tensor(Y_test_dropped).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model.train(epochs, X_train_dropped_device, X_test_dropped_device, Y_train_dropped_device, Y_test_dropped_device, alpha)\n",
    "dropped_model.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing results:\n",
      "accuracy: -0.0479463001438323 %\n",
      "precision: -0.07843513186308494 %\n",
      "recall: 0.01121076233184124 %\n",
      "f1: -0.033617208633270085 %\n"
     ]
    }
   ],
   "source": [
    "AlarmNet.compare_results(dropped_model.get_results(), model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Results\n",
    "- We can remove the bottom 8 features and have a model that only loses 0.1% precision, and even less for every other metric\n",
    "- A 4 feature model is almost perfect\n",
    "\n",
    "# Error Handling\n",
    "- The 12 initial features came from 4 sensors\n",
    "    - Temp/Humidity\n",
    "    - Pressure\n",
    "    - Volatile Organic Compounds (CO2, Ethanol, H2, TVOC)\n",
    "    - Particulate Matter (PM1, PM2.5, NC0.5, NC1, NC2.5)\n",
    "- 3 of these sensors are redundant, with the exception being the PM sensor\n",
    "    - This means that the features related to the PM sensor are twice as likely to be missing\n",
    "- We can simulate a real world scenario by introducing error according to this distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Add back the most correlated PM feature, so that all 4 sensors are used\n",
    "# PM0.5 is the most correlated PM feature, with index 5\n",
    "remaining_features_2 = list(remaining_features)\n",
    "remaining_features_2.append(ranking.index[5])\n",
    "X_error = data[remaining_features_2]\n",
    "# For each measurement, each sensor has this chance of introducing an error\n",
    "error_chance = 0.2\n",
    "\n",
    "# Introduce sensor errors\n",
    "\n",
    "VOC_features = [\n",
    "    'TVOC[ppb]',\n",
    "    'eCO2[ppm]',\n",
    "    'Raw H2',\n",
    "    'Raw Ethanol'\n",
    "]\n",
    "\n",
    "PM_features = [\n",
    "    'PM1.0',\n",
    "    'PM2.5',\n",
    "    'NC0.5',\n",
    "    'NC1.0',\n",
    "    'NC2.5'\n",
    "]\n",
    "\n",
    "th_features = [\n",
    "    'Temperature[C]',\n",
    "    'Humidity[%]'\n",
    "]\n",
    "pressure_features = [\n",
    "    'Pressure[hPa]'\n",
    "]\n",
    "\n",
    "# The PM sensor is twice as likely to fail due to lack of redundancy\n",
    "chances = [error_chance, error_chance*2, error_chance, error_chance]\n",
    "sensors = [VOC_features, PM_features, th_features, pressure_features]\n",
    "for datapoint in X_error.values:\n",
    "    errored_features = []\n",
    "    for i, sensor in enumerate(sensors):\n",
    "        sensor_error = random.random() < chances[i]\n",
    "        if sensor_error:\n",
    "            errored_features.extend(sensor)\n",
    "    errored_features = [feature for feature in errored_features if feature in X_error.columns]\n",
    "    for feature in errored_features:\n",
    "        datapoint[X_error.columns.get_loc(feature)] = np.nan\n",
    "\n",
    "X_train_error, X_test_error, Y_train_error, Y_test_error = train_test_split(X_error, Y_pred, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "- Replace each errored value with the mean of that feature from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute_train = imputer.fit_transform(X_train_error)\n",
    "X_impute_test = imputer.transform(X_test_error)\n",
    "\n",
    "X_impute_train = scaler.fit_transform(X_impute_train)\n",
    "X_impute_test = scaler.transform(X_impute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.23539188504219055\n",
      "Epoch 500 Loss: 0.003432096913456917\n",
      "Epoch 1000 Loss: 0.0012487940257415175\n",
      "Epoch 1500 Loss: 0.0005852619069628417\n",
      "Epoch 2000 Loss: 0.0003480861778371036\n",
      "Epoch 2500 Loss: 0.00023499401868321002\n",
      "Accuracy: 0.9999201660546064\n",
      "Precision: 1.0\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9999439493301945\n",
      "Confusion_matrix:\n",
      "[[3605    0]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 0.08782435129740421 %\n",
      "precision: 0.12316649871234597 %\n",
      "recall: 0.0 %\n",
      "f1: 0.061617745910819435 %\n"
     ]
    }
   ],
   "source": [
    "imputed_model = AlarmNet(\n",
    "    num_features=X_impute_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_impute_train_device = torch.tensor(X_impute_train).float().to(device)\n",
    "X_impute_test_device = torch.tensor(X_impute_test).float().to(device)\n",
    "Y_train_impute_device = torch.tensor(Y_train_error).float().view(-1, 1).to(device)\n",
    "Y_test_impute_device = torch.tensor(Y_test_error).float().view(-1, 1).to(device)\n",
    "\n",
    "imputed_model.train(\n",
    "    epochs,\n",
    "    X_impute_train_device,\n",
    "    X_impute_test_device,\n",
    "    Y_train_impute_device,\n",
    "    Y_test_impute_device,\n",
    "    alpha,\n",
    "    loss_fn = nn.MSELoss()\n",
    ")\n",
    "imputed_model.print_results()\n",
    "AlarmNet.compare_results(imputed_model.get_results(), dropped_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Modes\n",
    "- Current features:\n",
    "    - Humidity\n",
    "    - Raw Ethanol\n",
    "    - Pressure\n",
    "    - TVOC\n",
    "    - NC0.5\n",
    "- Sensors:\n",
    "    - Humidity\n",
    "    - Pressure\n",
    "    - Raw Ethanol/TVOC\n",
    "    - NC0.5\n",
    "- The model should be able to handle missing data in the case where at most 3 sensors have failed, because 4 failed sensors means no data\n",
    "    - 1 failed sensor = 4c1 = 4\n",
    "    - 2 failed sensors = 4c2 = 6\n",
    "    - 3 failed sensors = 4c3 = 4\n",
    "    - Total = 14\n",
    "## Ensemble Training\n",
    "- We can train 14 models that can predict the missing data for each error mode\n",
    "- In the case of error, we select the model that corresponds to the error mode and use it to predict the missing data\n",
    "- Then use the main model to predict the target\n",
    "### Indexing Ensemble\n",
    "- Columns should be rearranged according to sensors\n",
    "    - Humidity, Pressure, NC0.5, Ethanol, TVOC, \n",
    "- The error mode can be represented as a 4-bit value\n",
    "    - 0b0000 = No error\n",
    "    - 0b0001 = Ethanol/TVOC Error\n",
    "    - 0b0010 = NC0.5 Error\n",
    "    - 0b0100 = Pressure error\n",
    "    - 0b1000 = Humidity error\n",
    "- A 5-bit value can represent which features are missing\n",
    "    - 0b00000 = No error\n",
    "    - 0b00011 = Ethanol/TVOC Error\n",
    "    - 0b00100 = NC0.5 Error\n",
    "    - 0b01000 = Pressure error\n",
    "    - 0b10000 = Humidity error\n",
    "- We can convert from the 5-bit value to the 4-bit value with a simple shift right operation\n",
    "\n",
    "### Model Table\n",
    "- Store the models with an array\n",
    "- The index of the model is the error mode\n",
    "- Model 15 will always predict 1, because if all sensors have failed the worst should be assumed for safety\n",
    "- Model 0 will be the standard model trained on a full dataset\n",
    "- The rest of the arrays will be trained on the data with the corresponding error mode\n",
    "### New Model Type\n",
    "- A new model class will be created that will predict the missing values, construct the repaired dataset, call the standard model, and return the result\n",
    "### Ensemble Class\n",
    "- This new class will hold the model table and the standard model\n",
    "- It will be responsible for constructing the model address, calling the correct model, and returning the result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantPredictor(AlarmNet):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def predict(self, x):\n",
    "        return torch.tensor([self.val]*x.shape[0]).reshape(-1, 1).float()\n",
    "    def train(self, *args, **kwargs):\n",
    "        pass\n",
    "    def get_results(self):\n",
    "        return {\n",
    "            'accuracy': None,\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1': None,\n",
    "            'confusion_matrix': None,\n",
    "            'classification_report': None\n",
    "        }\n",
    "    def print_results(self):\n",
    "        super().print_results(self.get_results())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class DataPredictor(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print(100 * (results1 - results2) / results1)\n",
    "        \n",
    "    def __init__(self, error_mode, hidden_layers=[64,32], activation=nn.ReLU,):\n",
    "        super().__init__()\n",
    "        self.error_mode = error_mode\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        self.input_cols = []\n",
    "        self.output_cols = []\n",
    "        \n",
    "        #Error Mode is a 5 bit integer, with each bit representing a feature\n",
    "        # If the bit is 1, the feature is errored\n",
    "        output_features = 0\n",
    "        input_features = 0\n",
    "        for i in range(5):\n",
    "            if error_mode & (1 << i):\n",
    "                output_features += 1\n",
    "                self.output_cols.append(4-i)\n",
    "            else:\n",
    "                self.input_cols.append(4-i)\n",
    "        input_features = 5-output_features\n",
    "        \n",
    "\n",
    "        \n",
    "        self.stack_list = [nn.Linear(input_features, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])\n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], output_features)])\n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, epochs, X_train, X_test, alpha, loss_fn=nn.MSELoss(), Y_tr=None, Y_te=None,):\n",
    "\n",
    "        X_train_new = X_train[:, self.input_cols]\n",
    "        X_test_new = X_test[:, self.input_cols]\n",
    "        Y_train = X_train[:, self.output_cols]\n",
    "        Y_test = X_test[:, self.output_cols]\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = self.forward(X_train_new)\n",
    "            loss = loss_fn(Y_pred, Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        self.last_test = Y_test\n",
    "        self.last_pred = self.forward(X_test_new)\n",
    "        self.last_score = self.get_results(Y_test, self.last_pred)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "        Y_test = Y_test.cpu().detach().numpy()\n",
    "        Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        \n",
    "        self.last_score = r2_score(Y_test, Y_pred)\n",
    "        return self.last_score\n",
    "    def print_results(self):\n",
    "        if self.last_score is None:\n",
    "            self.get_results()\n",
    "        print('R2 score:', self.last_score)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with training for error mode 00011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9666537046432495\n"
     ]
    }
   ],
   "source": [
    "new_col_order = ['Humidity[%]', 'Pressure[hPa]', 'NC0.5', 'Raw Ethanol', 'TVOC[ppb]']\n",
    "new_data_drop = data[new_col_order]\n",
    "#rearrange so that order is humidity, pressure, NC0.5, Ethanol, TVOC\n",
    "\n",
    "X_train_5f, X_test_5f, Y_train_5f, Y_test_5f = train_test_split(new_data_drop, Y_pred, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_5f = scaler.fit_transform(X_train_5f)\n",
    "X_test_5f = scaler.transform(X_test_5f)\n",
    "layers = [64,32]\n",
    "predictor_3 = DataPredictor(0b00011, hidden_layers=layers).to(device)\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_5f).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_5f).float().view(-1, 1).to(device)\n",
    "predictor_3.train(epochs, X_train_5f_device, X_test_5f_device, alpha)\n",
    "predictor_3.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error_Predictor(AlarmNet):\n",
    "    def __init__(self, error_mode, hidden_layers=[64,32], activation=nn.ReLU, std_model: AlarmNet = None):\n",
    "        super().__init__(\n",
    "            pass_through=True\n",
    "        )\n",
    "        self.error_mode = error_mode\n",
    "        self.std_model = std_model\n",
    "        self.predictor = DataPredictor(error_mode, hidden_layers=hidden_layers, activation=activation)\n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha):\n",
    "        self.predictor.train(epochs, X_train, X_test, alpha)\n",
    "        self.last_pred = self.predict(X_test)\n",
    "        self.last_test = Y_test\n",
    "    def predict(self, X):\n",
    "        X_in = X[:, self.predictor.input_cols]\n",
    "        X_out = self.predictor.forward(X_in)\n",
    "        #Insert the predicted values into the original tensor\n",
    "        X[:, self.predictor.output_cols] = X_out\n",
    "        return self.std_model.predict(X)\n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "        return self.std_model.get_results(Y_test, Y_pred)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.699371874332428\n",
      "Epoch 500 Loss: 0.011745047755539417\n",
      "Epoch 1000 Loss: 0.06066644936800003\n",
      "Epoch 1500 Loss: 0.05417398363351822\n",
      "Epoch 2000 Loss: 0.05181897431612015\n",
      "Epoch 2500 Loss: 0.05028727650642395\n",
      "Accuracy: 0.9989621587098835\n",
      "Precision: 0.9986565158978952\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.999271831064807\n",
      "Confusion_matrix:\n",
      "[[3593   12]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_model = AlarmNet(\n",
    "    num_features=X_train_5f.shape[1],  # Update to match the new input dimensions\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "epochs = 3000\n",
    "alpha = 1e-2\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_5f).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_5f).float().view(-1, 1).to(device)\n",
    "\n",
    "std_model.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)\n",
    "\n",
    "std_model.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64,64]\n",
    "error_pred_3 = Error_Predictor(0b00011, hidden_layers=layers, std_model=std_model).to(device)\n",
    "error_pred_3.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9522593006546384\n",
      "Precision: 0.9583654587509638\n",
      "Recall: 0.9753390875462392\n",
      "F1: 0.9667777777777777\n",
      "Confusion_matrix:\n",
      "[[3227  378]\n",
      " [ 220 8701]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.90      0.92      3605\n",
      "         1.0       0.96      0.98      0.97      8921\n",
      "\n",
      "    accuracy                           0.95     12526\n",
      "   macro avg       0.95      0.94      0.94     12526\n",
      "weighted avg       0.95      0.95      0.95     12526\n",
      "\n",
      "Accuracy: 0.8855181223056043\n",
      "Precision: 0.8615860137158312\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9255992528795268\n",
      "Confusion_matrix:\n",
      "[[2172 1433]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.60      0.75      3605\n",
      "         1.0       0.86      1.00      0.93      8921\n",
      "\n",
      "    accuracy                           0.89     12526\n",
      "   macro avg       0.93      0.80      0.84     12526\n",
      "weighted avg       0.90      0.89      0.88     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 7.008718980549969 %\n",
      "precision: 10.098386179450278 %\n",
      "recall: -2.516952074474195 %\n",
      "f1: 4.259357821908496 %\n"
     ]
    }
   ],
   "source": [
    "Y_pred = error_pred_3.predict(X_test_5f_device)\n",
    "results_1 = error_pred_3.get_results(Y_test_5f_device, Y_pred)\n",
    "error_pred_3.print_results()\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute_test_1 = X_test_5f.copy()\n",
    "\n",
    "\n",
    "imputer.fit(X_impute_test_1)\n",
    "X_impute_test_1[:, error_pred_3.predictor.output_cols] = np.nan\n",
    "X_impute_test_1 = imputer.transform(X_impute_test_1)\n",
    "X_impute_test_1_device = torch.tensor(X_impute_test_1).float().to(device)\n",
    "\n",
    "\n",
    "Y_pred_std = std_model.predict(X_impute_test_1_device)\n",
    "results_2 = std_model.get_results(Y_test_impute_device, Y_pred_std)\n",
    "std_model.print_results()\n",
    "\n",
    "AlarmNet.compare_results(results_1, results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Error Predictor with 2 errors\n",
    "-The predictor is much more likely to predict a false negative than the imputer, making this not the right choice for a fire alarm\n",
    "- Hopefully this changes in the case of the full ensemble\n",
    "- Compared to the imputer method, the predictor is better in all metrics except for recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
