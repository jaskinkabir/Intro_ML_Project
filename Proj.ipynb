{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'smoke_detection_iot.csv'\n",
    "\n",
    "data = pd.read_csv(path).drop(['Unnamed: 0', 'UTC', 'CNT'], axis=1)\n",
    "Y_df = data['Fire Alarm']\n",
    "X_df = data.drop('Fire Alarm', axis=1)\n",
    "\n",
    "Y_test_raw = X_df.values\n",
    "Y_raw = Y_df.values\n",
    "\n",
    "X_train_raw, X_test_raw, Y_train_raw, Y_test_raw = train_test_split(Y_test_raw, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_raw = scaler.fit_transform(X_train_raw)\n",
    "X_test_raw = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7198435068130493\n",
      "Epoch 500 Loss: 0.003261410864070058\n",
      "Epoch 1000 Loss: 0.003031389322131872\n",
      "Epoch 1500 Loss: 0.001642040559090674\n",
      "Epoch 2000 Loss: 0.0010461597703397274\n",
      "Epoch 2500 Loss: 0.0006817225366830826\n",
      "Accuracy: 0.9997604981638193\n",
      "Precision: 0.9998878923766816\n",
      "Recall: 0.9997758098867839\n",
      "F1: 0.9998318479905834\n",
      "Confusion_matrix:\n",
      "[[3604    1]\n",
      " [   2 8919]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from alarmnetclass import AlarmNet\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "alpha = 1e-2\n",
    "epochs = 3000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "full_model = AlarmNet(\n",
    "    num_features=X_train_raw.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_raw_device = torch.tensor(X_train_raw).float().to(device)\n",
    "X_test_raw_device = torch.tensor(X_test_raw).float().to(device)\n",
    "Y_train_raw_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_raw_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "full_model.train(epochs, X_train_raw_device, X_test_raw_device, Y_train_raw_device, Y_test_raw_device, alpha)\n",
    "full_model.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "- Initially there are 15 features\n",
    "- 3 are unusable\n",
    "    - UTC Timestamp\n",
    "    - CNT\n",
    "    - Unnamed: 0\n",
    "- 12 features are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humidity[%]       0.399846\n",
      "Raw Ethanol       0.340652\n",
      "Pressure[hPa]     0.249797\n",
      "TVOC[ppb]         0.214743\n",
      "Temperature[C]    0.163902\n",
      "NC0.5             0.128118\n",
      "PM1.0             0.110552\n",
      "Raw H2            0.107007\n",
      "eCO2[ppm]         0.097006\n",
      "PM2.5             0.084916\n",
      "NC1.0             0.082828\n",
      "NC2.5             0.057707\n",
      "Name: Fire Alarm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "corr = np.abs(data.corr())\n",
    "ranking = corr['Fire Alarm'].sort_values(ascending=False)[1:]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: Index(['Humidity[%]', 'Raw Ethanol', 'Pressure[hPa]', 'TVOC[ppb]'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_drops = 8\n",
    "remaining_features = ranking.index[:-num_drops]\n",
    "\n",
    "\n",
    "X_df_dropped = data[remaining_features]\n",
    "print('Remaining features:', X_df_dropped.columns)\n",
    "X_train_dropped, X_test_dropped, Y_train_dropped, Y_test_dropped = train_test_split(X_df_dropped.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.transform(X_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.732650637626648\n",
      "Epoch 500 Loss: 0.05563681572675705\n",
      "Epoch 1000 Loss: 0.28884029388427734\n",
      "Epoch 1500 Loss: 0.050261083990335464\n",
      "Epoch 2000 Loss: 0.054096970707178116\n",
      "Epoch 2500 Loss: 0.05253012850880623\n",
      "Accuracy: 0.999041992655277\n",
      "Precision: 0.9987683350128765\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9993278064082456\n",
      "Confusion_matrix:\n",
      "[[3594   11]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -0.07191945021575956 %\n",
      "precision: -0.1120937983872563 %\n",
      "recall: 0.01121076233184124 %\n",
      "f1: -0.050438062376095244 %\n"
     ]
    }
   ],
   "source": [
    "dropped_model = AlarmNet(\n",
    "    num_features=X_train_dropped.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_dropped_device = torch.tensor(X_train_dropped).float().to(device)\n",
    "X_test_dropped_device = torch.tensor(X_test_dropped).float().to(device)\n",
    "Y_train_dropped_device = torch.tensor(Y_train_dropped).float().view(-1, 1).to(device)\n",
    "Y_test_dropped_device = torch.tensor(Y_test_dropped).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model.train(epochs, X_train_dropped_device, X_test_dropped_device, Y_train_dropped_device, Y_test_dropped_device, alpha)\n",
    "dropped_model.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model.get_results(), full_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Results\n",
    "- We can remove the bottom 8 features and have a model that only loses 0.1% precision, and even less for every other metric\n",
    "- A 4 feature model is almost perfect\n",
    "    - These features are:\n",
    "        - Humidity\n",
    "        - Raw Ethanol\n",
    "        - Pressure\n",
    "        - TVOC\n",
    "\n",
    "# Error Handling\n",
    "- The 12 initial features came from 4 sensors\n",
    "    - Temp/Humidity\n",
    "    - Pressure\n",
    "    - Volatile Organic Compounds (CO2, Ethanol, H2, TVOC)\n",
    "    - Particulate Matter (PM1, PM2.5, NC0.5, NC1, NC2.5)\n",
    "- 3 of these sensors are redundant, with the exception being the PM sensor\n",
    "    - This means that the features related to the PM sensor are twice as likely to be missing\n",
    "- We can simulate a real world scenario by introducing error according to this distribution\n",
    "- Note that the Particulate Matter sensor is not included in the 4-feature model.\n",
    "    - To add redundancy to our model, we can add back the most correlated feature from the PM sensor\n",
    "    - This feature is PM0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add back the most correlated PM feature, so that all 4 sensors are used\n",
    "# PM0.5 is the most correlated PM feature, with index 5\n",
    "remaining_features_2 = list(remaining_features)\n",
    "remaining_features_2.append(ranking.index[5])\n",
    "X_5f = data[remaining_features_2]\n",
    "X_train_5f, X_test_5f, Y_train_5f, Y_test_5f = train_test_split(X_5f.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_5f = scaler.fit_transform(X_train_5f)\n",
    "X_test_5f = scaler.transform(X_test_5f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6647908091545105\n",
      "Epoch 500 Loss: 0.012231706641614437\n",
      "Epoch 1000 Loss: 0.04820350557565689\n",
      "Epoch 1500 Loss: 0.008142990991473198\n",
      "Epoch 2000 Loss: 0.0044751642271876335\n",
      "Epoch 2500 Loss: 0.002745460020378232\n",
      "Accuracy: 0.9997604981638193\n",
      "Precision: 0.9998878923766816\n",
      "Recall: 0.9997758098867839\n",
      "F1: 0.9998318479905834\n",
      "Confusion_matrix:\n",
      "[[3604    1]\n",
      " [   2 8919]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 0.0 %\n",
      "precision: 0.0 %\n",
      "recall: 0.0 %\n",
      "f1: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropped_model_5 = AlarmNet(\n",
    "    num_features=X_train_5f.shape[1],  # Update to match the new input dimensions\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "epochs = 3000\n",
    "alpha = 1e-2\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model_5.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)\n",
    "\n",
    "dropped_model_5_results = dropped_model_5.get_results()\n",
    "dropped_model_5.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model_5_results, full_model.get_results())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Introduce sensor errors\n",
    "\n",
    "VOC_features = [\n",
    "    'TVOC[ppb]',\n",
    "    'eCO2[ppm]',\n",
    "    'Raw H2',\n",
    "    'Raw Ethanol'\n",
    "]\n",
    "\n",
    "PM_features = [\n",
    "    'PM1.0',\n",
    "    'PM2.5',\n",
    "    'NC0.5',\n",
    "    'NC1.0',\n",
    "    'NC2.5'\n",
    "]\n",
    "\n",
    "th_features = [\n",
    "    'Temperature[C]',\n",
    "    'Humidity[%]'\n",
    "]\n",
    "pressure_features = [\n",
    "    'Pressure[hPa]'\n",
    "]\n",
    "\n",
    "# For each measurement, each sensor has this chance of introducing an error\n",
    "error_chance = 0.2\n",
    "\n",
    "# The PM sensor is twice as likely to fail due to lack of redundancy\n",
    "chances = [error_chance, error_chance*2, error_chance, error_chance]\n",
    "sensors = [VOC_features, PM_features, th_features, pressure_features]\n",
    "\n",
    "error_mask = np.ones(X_5f.shape)\n",
    "\n",
    "# for i, row in error_mask:\n",
    "#     errored_features = []\n",
    "#     for j, sensor in enumerate(sensors):\n",
    "#         sensor_error = random.random() < chances[j]\n",
    "#         if sensor_error:\n",
    "#             errored_features.extend(sensor)\n",
    "#     errored_features = [feature for feature in errored_features if feature in X_error.columns]\n",
    "#     if errored_features:\n",
    "#         for feature in errored_features:\n",
    "#             error_mask[i][X_error.columns.get_loc(feature)] = np.nan\n",
    "#         print(i, error_mask[i])\n",
    "\n",
    "X_error_np = X_5f.values.copy()\n",
    "for i, datapoint in enumerate(X_5f.values):\n",
    "    errored_features = []\n",
    "    for j, sensor in enumerate(sensors):\n",
    "        sensor_error = random.random() < chances[j]\n",
    "        if sensor_error:\n",
    "            errored_features.extend(sensor)\n",
    "    errored_features = [feature for feature in errored_features if feature in X_5f.columns]\n",
    "    if errored_features:\n",
    "        for feature in errored_features:\n",
    "            X_error_np[i][X_5f.columns.get_loc(feature)] = np.nan\n",
    "        # print(i, X_error_np[i])\n",
    "\n",
    "X_train_error, X_test_error, Y_train_error, Y_test_error = train_test_split(X_error_np, Y_raw, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "- Replace each errored value with the mean of that feature from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_5f.values)\n",
    "imputer.fit(X_train_error)\n",
    "X_impute_train = imputer.transform(X_train_error)\n",
    "X_impute_test = imputer.transform(X_test_error)\n",
    "\n",
    "X_impute_train = scaler.fit_transform(X_impute_train)\n",
    "X_impute_test = scaler.transform(X_impute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7042819261550903\n",
      "Epoch 500 Loss: 0.17240461707115173\n",
      "Epoch 1000 Loss: 0.139237180352211\n",
      "Epoch 1500 Loss: 0.11427774280309677\n",
      "Epoch 2000 Loss: 0.07477901875972748\n",
      "Epoch 2500 Loss: 0.0588216632604599\n",
      "Epoch 3000 Loss: 0.05080319568514824\n",
      "Epoch 3500 Loss: 0.04612872377038002\n",
      "Epoch 4000 Loss: 0.04302603378891945\n",
      "Epoch 4500 Loss: 0.040812019258737564\n",
      "Epoch 5000 Loss: 0.03922854736447334\n",
      "Epoch 5500 Loss: 0.038085728883743286\n",
      "Epoch 6000 Loss: 0.03717287257313728\n",
      "Epoch 6500 Loss: 0.03650260344147682\n",
      "Epoch 7000 Loss: 0.03597822040319443\n",
      "Epoch 7500 Loss: 0.03550107032060623\n",
      "Epoch 8000 Loss: 0.035160601139068604\n",
      "Epoch 8500 Loss: 0.03483729064464569\n",
      "Epoch 9000 Loss: 0.03457602858543396\n",
      "Epoch 9500 Loss: 0.03438257798552513\n",
      "Epoch 10000 Loss: 0.03420368954539299\n",
      "Epoch 10500 Loss: 0.03404993191361427\n",
      "Epoch 11000 Loss: 0.03393172100186348\n",
      "Epoch 11500 Loss: 0.03380455821752548\n",
      "Epoch 12000 Loss: 0.03366152197122574\n",
      "Epoch 12500 Loss: 0.033522527664899826\n",
      "Epoch 13000 Loss: 0.03341270238161087\n",
      "Epoch 13500 Loss: 0.03335200622677803\n",
      "Epoch 14000 Loss: 0.03328842297196388\n",
      "Epoch 14500 Loss: 0.03315548598766327\n",
      "Epoch 15000 Loss: 0.03310535103082657\n",
      "Epoch 15500 Loss: 0.033047690987586975\n",
      "Accuracy: 0.9850710522114002\n",
      "Precision: 0.9846836847946726\n",
      "Recall: 0.9945073422262078\n",
      "F1: 0.9895711337906419\n",
      "Confusion_matrix:\n",
      "[[3467  138]\n",
      " [  49 8872]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.97      3605\n",
      "         1.0       0.98      0.99      0.99      8921\n",
      "\n",
      "    accuracy                           0.99     12526\n",
      "   macro avg       0.99      0.98      0.98     12526\n",
      "weighted avg       0.99      0.99      0.99     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -1.4912067428478897 %\n",
      "precision: -1.5440702244578595 %\n",
      "recall: -0.5297565374210924 %\n",
      "f1: -1.0368849544587029 %\n"
     ]
    }
   ],
   "source": [
    "imputed_model = AlarmNet(\n",
    "    num_features=X_impute_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[128, 256, 128]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_impute_train_device = torch.tensor(X_impute_train).float().to(device)\n",
    "X_impute_test_device = torch.tensor(X_impute_test).float().to(device)\n",
    "Y_train_impute_device = torch.tensor(Y_train_error).float().view(-1, 1).to(device)\n",
    "Y_test_impute_device = torch.tensor(Y_test_error).float().view(-1, 1).to(device)\n",
    "\n",
    "imputed_model.train(\n",
    "    epochs= 16000,\n",
    "    X_train = X_impute_train_device,\n",
    "    X_test = X_impute_test_device,\n",
    "    Y_train = Y_train_impute_device,\n",
    "    Y_test = Y_test_impute_device,\n",
    "    alpha= 1e-4,\n",
    "    loss_fn = nn.BCELoss(),\n",
    "    optimizer = torch.optim.Adam\n",
    ")\n",
    "imputed_model.print_results()\n",
    "AlarmNet.compare_results(imputed_model.get_results(), dropped_model_5.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Modes\n",
    "- Current features:\n",
    "    - Humidity\n",
    "    - Raw Ethanol\n",
    "    - Pressure\n",
    "    - TVOC\n",
    "    - NC0.5\n",
    "- Sensors:\n",
    "    - Humidity\n",
    "    - Pressure\n",
    "    - Raw Ethanol/TVOC\n",
    "    - NC0.5\n",
    "- The model should be able to handle missing data in the case where at most 3 sensors have failed, because 4 failed sensors means no data\n",
    "    - 1 failed sensor = 4c1 = 4\n",
    "    - 2 failed sensors = 4c2 = 6\n",
    "    - 3 failed sensors = 4c3 = 4\n",
    "    - Total = 14\n",
    "## Ensemble Training\n",
    "- We can train 14 models that can predict the missing data for each error mode\n",
    "- In the case of error, we select the model that corresponds to the error mode and use it to predict the missing data\n",
    "- Then use the main model to predict the target\n",
    "### Indexing Ensemble\n",
    "- Columns should be rearranged according to sensors\n",
    "    - Humidity, Pressure, NC0.5, Ethanol, TVOC, \n",
    "- The error mode can be represented as a 4-bit value\n",
    "    - 0b0000 = No error\n",
    "    - 0b0001 = Ethanol/TVOC Error\n",
    "    - 0b0010 = NC0.5 Error\n",
    "    - 0b0100 = Pressure error\n",
    "    - 0b1000 = Humidity error\n",
    "- A 5-bit value can represent which features are missing\n",
    "    - 0b00000 = No error\n",
    "    - 0b00011 = Ethanol/TVOC Error\n",
    "    - 0b00100 = NC0.5 Error\n",
    "    - 0b01000 = Pressure error\n",
    "    - 0b10000 = Humidity error\n",
    "- We can convert from the 5-bit value to the 4-bit value with a simple shift right operation\n",
    "\n",
    "### Model Table\n",
    "- Store the models with an array\n",
    "- The index of the model is the error mode\n",
    "- Model 15 will always predict 1, because if all sensors have failed the worst should be assumed for safety\n",
    "- Model 0 will be the standard model trained on a full dataset\n",
    "- The rest of the arrays will be trained on the data with the corresponding error mode\n",
    "### New Model Type\n",
    "- A new model class will be created that will predict the missing values, construct the repaired dataset, call the standard model, and return the result\n",
    "### Ensemble Class\n",
    "- This new class will hold the model table and the standard model\n",
    "- It will be responsible for constructing the model address, calling the correct model, and returning the result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
