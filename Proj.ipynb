{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'smoke_detection_iot.csv'\n",
    "\n",
    "data = pd.read_csv(path).drop(['Unnamed: 0', 'UTC', 'CNT'], axis=1)\n",
    "Y_df = data['Fire Alarm']\n",
    "X_df = data.drop('Fire Alarm', axis=1)\n",
    "\n",
    "Y_test_raw = X_df.values\n",
    "Y_raw = Y_df.values\n",
    "\n",
    "X_train_raw, X_test_raw, Y_train_raw, Y_test_raw = train_test_split(Y_test_raw, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_raw = scaler.fit_transform(X_train_raw)\n",
    "X_test_raw = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7049118876457214\n",
      "Epoch 500 Loss: 0.004323865752667189\n",
      "Epoch 1000 Loss: 0.0011660805903375149\n",
      "Epoch 1500 Loss: 0.0005272722337394953\n",
      "Epoch 2000 Loss: 0.0002978374541271478\n",
      "Epoch 2500 Loss: 0.00020019464136566967\n",
      "Accuracy: 0.9997604981638193\n",
      "Precision: 0.9998878923766816\n",
      "Recall: 0.9997758098867839\n",
      "F1: 0.9998318479905834\n",
      "Confusion_matrix:\n",
      "[[3604    1]\n",
      " [   2 8919]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from alarmnetclass import AlarmNet\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "alpha = 1e-2\n",
    "epochs = 3000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "full_model = AlarmNet(\n",
    "    num_features=X_train_raw.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_raw_device = torch.tensor(X_train_raw).float().to(device)\n",
    "X_test_raw_device = torch.tensor(X_test_raw).float().to(device)\n",
    "Y_train_raw_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_raw_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "full_model.train(epochs, X_train_raw_device, X_test_raw_device, Y_train_raw_device, Y_test_raw_device, alpha)\n",
    "full_model.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "- Initially there are 15 features\n",
    "- 3 are unusable\n",
    "    - UTC Timestamp\n",
    "    - CNT\n",
    "    - Unnamed: 0\n",
    "- 12 features are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humidity[%]       0.399846\n",
      "Raw Ethanol       0.340652\n",
      "Pressure[hPa]     0.249797\n",
      "TVOC[ppb]         0.214743\n",
      "Temperature[C]    0.163902\n",
      "NC0.5             0.128118\n",
      "PM1.0             0.110552\n",
      "Raw H2            0.107007\n",
      "eCO2[ppm]         0.097006\n",
      "PM2.5             0.084916\n",
      "NC1.0             0.082828\n",
      "NC2.5             0.057707\n",
      "Name: Fire Alarm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "corr = np.abs(data.corr())\n",
    "ranking = corr['Fire Alarm'].sort_values(ascending=False)[1:]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: Index(['Humidity[%]', 'Raw Ethanol', 'Pressure[hPa]', 'TVOC[ppb]'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_drops = 8\n",
    "remaining_features = ranking.index[:-num_drops]\n",
    "\n",
    "\n",
    "X_df_dropped = data[remaining_features]\n",
    "print('Remaining features:', X_df_dropped.columns)\n",
    "X_train_dropped, X_test_dropped, Y_train_dropped, Y_test_dropped = train_test_split(X_df_dropped.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.transform(X_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6880698204040527\n",
      "Epoch 500 Loss: 0.011641676537692547\n",
      "Epoch 1000 Loss: 0.008120225742459297\n",
      "Epoch 1500 Loss: 0.0028617423959076405\n",
      "Epoch 2000 Loss: 0.0012854200322180986\n",
      "Epoch 2500 Loss: 0.04466460645198822\n",
      "Accuracy: 0.999041992655277\n",
      "Precision: 0.9987683350128765\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9993278064082456\n",
      "Confusion_matrix:\n",
      "[[3594   11]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -0.07191945021575956 %\n",
      "precision: -0.1120937983872563 %\n",
      "recall: 0.01121076233184124 %\n",
      "f1: -0.050438062376095244 %\n"
     ]
    }
   ],
   "source": [
    "dropped_model = AlarmNet(\n",
    "    num_features=X_train_dropped.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_dropped_device = torch.tensor(X_train_dropped).float().to(device)\n",
    "X_test_dropped_device = torch.tensor(X_test_dropped).float().to(device)\n",
    "Y_train_dropped_device = torch.tensor(Y_train_dropped).float().view(-1, 1).to(device)\n",
    "Y_test_dropped_device = torch.tensor(Y_test_dropped).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model.train(epochs, X_train_dropped_device, X_test_dropped_device, Y_train_dropped_device, Y_test_dropped_device, alpha)\n",
    "dropped_model.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model.get_results(), full_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Results\n",
    "- We can remove the bottom 8 features and have a model that only loses 0.1% precision, and even less for every other metric\n",
    "- A 4 feature model is almost perfect\n",
    "    - These features are:\n",
    "        - Humidity\n",
    "        - Raw Ethanol\n",
    "        - Pressure\n",
    "        - TVOC\n",
    "\n",
    "# Error Handling\n",
    "- The 12 initial features came from 4 sensors\n",
    "    - Temp/Humidity\n",
    "    - Pressure\n",
    "    - Volatile Organic Compounds (CO2, Ethanol, H2, TVOC)\n",
    "    - Particulate Matter (PM1, PM2.5, NC0.5, NC1, NC2.5)\n",
    "- 3 of these sensors are redundant, with the exception being the PM sensor\n",
    "    - This means that the features related to the PM sensor are twice as likely to be missing\n",
    "- We can simulate a real world scenario by introducing error according to this distribution\n",
    "- Note that the Particulate Matter sensor is not included in the 4-feature model.\n",
    "    - To add redundancy to our model, we can add back the most correlated feature from the PM sensor\n",
    "    - This feature is PM0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add back the most correlated PM feature, so that all 4 sensors are used\n",
    "# PM0.5 is the most correlated PM feature, with index 5\n",
    "remaining_features_2 = list(remaining_features)\n",
    "remaining_features_2.append(ranking.index[5])\n",
    "X_5f = data[remaining_features_2]\n",
    "X_train_5f, X_test_5f, Y_train_5f, Y_test_5f = train_test_split(X_5f.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_5f = scaler.fit_transform(X_train_5f)\n",
    "X_test_5f = scaler.transform(X_test_5f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.702659547328949\n",
      "Epoch 500 Loss: 0.010820690542459488\n",
      "Epoch 1000 Loss: 0.056103769689798355\n",
      "Epoch 1500 Loss: 0.04936439171433449\n",
      "Epoch 2000 Loss: 0.04711180180311203\n",
      "Epoch 2500 Loss: 0.04596996307373047\n",
      "Accuracy: 0.9998403321092129\n",
      "Precision: 1.0\n",
      "Recall: 0.9997758098867839\n",
      "F1: 0.9998878923766816\n",
      "Confusion_matrix:\n",
      "[[3605    0]\n",
      " [   2 8919]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 0.007984669434684304 %\n",
      "precision: 0.011210762331836932 %\n",
      "recall: 0.0 %\n",
      "f1: 0.00560506698055636 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropped_model_5 = AlarmNet(\n",
    "    num_features=X_train_5f.shape[1],  # Update to match the new input dimensions\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "epochs = 3000\n",
    "alpha = 1e-2\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model_5.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)\n",
    "\n",
    "dropped_model_5_results = dropped_model_5.get_results()\n",
    "dropped_model_5.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model_5_results, full_model.get_results())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Introduce sensor errors\n",
    "\n",
    "VOC_features = [\n",
    "    'TVOC[ppb]',\n",
    "    'eCO2[ppm]',\n",
    "    'Raw H2',\n",
    "    'Raw Ethanol'\n",
    "]\n",
    "\n",
    "PM_features = [\n",
    "    'PM1.0',\n",
    "    'PM2.5',\n",
    "    'NC0.5',\n",
    "    'NC1.0',\n",
    "    'NC2.5'\n",
    "]\n",
    "\n",
    "th_features = [\n",
    "    'Temperature[C]',\n",
    "    'Humidity[%]'\n",
    "]\n",
    "pressure_features = [\n",
    "    'Pressure[hPa]'\n",
    "]\n",
    "\n",
    "# For each measurement, each sensor has this chance of introducing an error\n",
    "error_chance = 0.2\n",
    "\n",
    "# The PM sensor is twice as likely to fail due to lack of redundancy\n",
    "chances = [error_chance, error_chance*2, error_chance, error_chance]\n",
    "sensors = [VOC_features, PM_features, th_features, pressure_features]\n",
    "\n",
    "error_mask = np.ones(X_5f.shape)\n",
    "\n",
    "# for i, row in error_mask:\n",
    "#     errored_features = []\n",
    "#     for j, sensor in enumerate(sensors):\n",
    "#         sensor_error = random.random() < chances[j]\n",
    "#         if sensor_error:\n",
    "#             errored_features.extend(sensor)\n",
    "#     errored_features = [feature for feature in errored_features if feature in X_error.columns]\n",
    "#     if errored_features:\n",
    "#         for feature in errored_features:\n",
    "#             error_mask[i][X_error.columns.get_loc(feature)] = np.nan\n",
    "#         print(i, error_mask[i])\n",
    "\n",
    "X_error_np = X_5f.values.copy()\n",
    "for i, datapoint in enumerate(X_5f.values):\n",
    "    errored_features = []\n",
    "    for j, sensor in enumerate(sensors):\n",
    "        sensor_error = random.random() < chances[j]\n",
    "        if sensor_error:\n",
    "            errored_features.extend(sensor)\n",
    "    errored_features = [feature for feature in errored_features if feature in X_5f.columns]\n",
    "    if errored_features:\n",
    "        for feature in errored_features:\n",
    "            X_error_np[i][X_5f.columns.get_loc(feature)] = np.nan\n",
    "        # print(i, X_error_np[i])\n",
    "\n",
    "X_train_error, X_test_error, Y_train_error, Y_test_error = train_test_split(X_error_np, Y_raw, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "- Replace each errored value with the mean of that feature from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_5f.values)\n",
    "X_impute_train = imputer.transform(X_train_error)\n",
    "X_impute_test = imputer.transform(X_test_error)\n",
    "\n",
    "X_impute_train = scaler.fit_transform(X_impute_train)\n",
    "X_impute_test = scaler.transform(X_impute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.25850191712379456\n",
      "Epoch 500 Loss: 0.019104836508631706\n",
      "Epoch 1000 Loss: 0.015230805613100529\n",
      "Epoch 1500 Loss: 0.01412381324917078\n",
      "Epoch 2000 Loss: 0.018488258123397827\n",
      "Epoch 2500 Loss: 0.013979995623230934\n",
      "Accuracy: 0.9817978604502634\n",
      "Precision: 0.9791643699702348\n",
      "Recall: 0.9956282927922878\n",
      "F1: 0.9873277012005336\n",
      "Confusion_matrix:\n",
      "[[3416  189]\n",
      " [  39 8882]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97      3605\n",
      "         1.0       0.98      1.00      0.99      8921\n",
      "\n",
      "    accuracy                           0.98     12526\n",
      "   macro avg       0.98      0.97      0.98     12526\n",
      "weighted avg       0.98      0.98      0.98     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -1.756383151731996 %\n",
      "precision: -2.002111764262588 %\n",
      "recall: -0.4278315694663381 %\n",
      "f1: -1.2154125923055294 %\n"
     ]
    }
   ],
   "source": [
    "imputed_model = AlarmNet(\n",
    "    num_features=X_impute_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_impute_train_device = torch.tensor(X_impute_train).float().to(device)\n",
    "X_impute_test_device = torch.tensor(X_impute_test).float().to(device)\n",
    "Y_train_impute_device = torch.tensor(Y_train_error).float().view(-1, 1).to(device)\n",
    "Y_test_impute_device = torch.tensor(Y_test_error).float().view(-1, 1).to(device)\n",
    "\n",
    "imputed_model.train(\n",
    "    epochs,\n",
    "    X_impute_train_device,\n",
    "    X_impute_test_device,\n",
    "    Y_train_impute_device,\n",
    "    Y_test_impute_device,\n",
    "    alpha,\n",
    "    loss_fn = nn.MSELoss()\n",
    ")\n",
    "imputed_model.print_results()\n",
    "AlarmNet.compare_results(imputed_model.get_results(), dropped_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Modes\n",
    "- Current features:\n",
    "    - Humidity\n",
    "    - Raw Ethanol\n",
    "    - Pressure\n",
    "    - TVOC\n",
    "    - NC0.5\n",
    "- Sensors:\n",
    "    - Humidity\n",
    "    - Pressure\n",
    "    - Raw Ethanol/TVOC\n",
    "    - NC0.5\n",
    "- The model should be able to handle missing data in the case where at most 3 sensors have failed, because 4 failed sensors means no data\n",
    "    - 1 failed sensor = 4c1 = 4\n",
    "    - 2 failed sensors = 4c2 = 6\n",
    "    - 3 failed sensors = 4c3 = 4\n",
    "    - Total = 14\n",
    "## Ensemble Training\n",
    "- We can train 14 models that can predict the missing data for each error mode\n",
    "- In the case of error, we select the model that corresponds to the error mode and use it to predict the missing data\n",
    "- Then use the main model to predict the target\n",
    "### Indexing Ensemble\n",
    "- Columns should be rearranged according to sensors\n",
    "    - Humidity, Pressure, NC0.5, Ethanol, TVOC, \n",
    "- The error mode can be represented as a 4-bit value\n",
    "    - 0b0000 = No error\n",
    "    - 0b0001 = Ethanol/TVOC Error\n",
    "    - 0b0010 = NC0.5 Error\n",
    "    - 0b0100 = Pressure error\n",
    "    - 0b1000 = Humidity error\n",
    "- A 5-bit value can represent which features are missing\n",
    "    - 0b00000 = No error\n",
    "    - 0b00011 = Ethanol/TVOC Error\n",
    "    - 0b00100 = NC0.5 Error\n",
    "    - 0b01000 = Pressure error\n",
    "    - 0b10000 = Humidity error\n",
    "- We can convert from the 5-bit value to the 4-bit value with a simple shift right operation\n",
    "\n",
    "### Model Table\n",
    "- Store the models with an array\n",
    "- The index of the model is the error mode\n",
    "- Model 15 will always predict 1, because if all sensors have failed the worst should be assumed for safety\n",
    "- Model 0 will be the standard model trained on a full dataset\n",
    "- The rest of the arrays will be trained on the data with the corresponding error mode\n",
    "### New Model Type\n",
    "- A new model class will be created that will predict the missing values, construct the repaired dataset, call the standard model, and return the result\n",
    "### Ensemble Class\n",
    "- This new class will hold the model table and the standard model\n",
    "- It will be responsible for constructing the model address, calling the correct model, and returning the result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantPredictor(AlarmNet):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def predict(self, x):\n",
    "        return torch.tensor([self.val]*x.shape[0]).reshape(-1, 1).float()\n",
    "    def train(self, *args, **kwargs):\n",
    "        pass\n",
    "    def get_results(self):\n",
    "        return {\n",
    "            'accuracy': None,\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1': None,\n",
    "            'confusion_matrix': None,\n",
    "            'classification_report': None\n",
    "        }\n",
    "    def print_results(self):\n",
    "        super().print_results(self.get_results())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class DataPredictor(nn.Module):\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print(100 * (results1 - results2) / results1)\n",
    "        \n",
    "    def __init__(self, error_mode, hidden_layers=[64,32], activation=nn.Tanh,):\n",
    "        super().__init__()\n",
    "        self.error_mode = error_mode\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        self.input_cols = []\n",
    "        self.output_cols = []\n",
    "        \n",
    "        #Error Mode is a 5 bit integer, with each bit representing a feature\n",
    "        # If the bit is 1, the feature is errored\n",
    "        output_features = 0\n",
    "        input_features = 0\n",
    "        for i in range(5):\n",
    "            if error_mode & (1 << i):\n",
    "                output_features += 1\n",
    "                self.output_cols.append(4-i)\n",
    "            else:\n",
    "                self.input_cols.append(4-i)\n",
    "        input_features = 5-output_features\n",
    "        \n",
    "\n",
    "        \n",
    "        self.stack_list = [nn.Linear(input_features, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])\n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], output_features)])\n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, epochs, X_train, X_test, alpha, loss_fn=nn.MSELoss(), Y_tr=None, Y_te=None,):\n",
    "\n",
    "        X_train_new = X_train[:, self.input_cols]\n",
    "        X_test_new = X_test[:, self.input_cols]\n",
    "        Y_train = X_train[:, self.output_cols]\n",
    "        Y_test = X_test[:, self.output_cols]\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = self.forward(X_train_new)\n",
    "            loss = loss_fn(Y_pred, Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        self.last_test = Y_test\n",
    "        self.last_pred = self.forward(X_test_new)\n",
    "        self.last_score = self.get_results(Y_test, self.last_pred)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "        Y_test = Y_test.cpu().detach().numpy()\n",
    "        Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        \n",
    "        self.last_score = r2_score(Y_test, Y_pred)\n",
    "        return self.last_score\n",
    "    def print_results(self):\n",
    "        if self.last_score is None:\n",
    "            self.get_results()\n",
    "        print('R2 score:', self.last_score)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with training for error mode 00011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9676176309585571\n"
     ]
    }
   ],
   "source": [
    "new_col_order = ['Humidity[%]', 'Pressure[hPa]', 'NC0.5', 'Raw Ethanol', 'TVOC[ppb]']\n",
    "new_data_drop = data[new_col_order]\n",
    "#rearrange so that order is humidity, pressure, NC0.5, Ethanol, TVOC\n",
    "\n",
    "X_train_5f, X_test_5f, Y_train_raw, Y_test_raw = train_test_split(new_data_drop, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_5f = scaler.fit_transform(X_train_5f)\n",
    "X_test_5f = scaler.transform(X_test_5f)\n",
    "layers = [64,32]\n",
    "predictor_3 = DataPredictor(0b00011, hidden_layers=layers).to(device)\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "predictor_3.train(epochs, X_train_5f_device, X_test_5f_device, alpha)\n",
    "predictor_3.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error_Predictor(AlarmNet):\n",
    "    def __init__(self, error_mode, hidden_layers=[64,32], activation=nn.ReLU, std_model: AlarmNet = None):\n",
    "        super().__init__(\n",
    "            pass_through=True\n",
    "        )\n",
    "        self.error_mode = error_mode\n",
    "        self.std_model = std_model\n",
    "        self.predictor = DataPredictor(error_mode, hidden_layers=hidden_layers, activation=activation)\n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha):\n",
    "        self.predictor.train(epochs, X_train, X_test, alpha)\n",
    "        self.last_pred = self.predict(X_test)\n",
    "        self.last_test = Y_test\n",
    "    def predict(self, X):\n",
    "        X_in = X[:, self.predictor.input_cols]\n",
    "        X_out = self.predictor.forward(X_in)\n",
    "        #Insert the predicted values into the original tensor\n",
    "        X[:, self.predictor.output_cols] = X_out\n",
    "        return self.std_model.predict(X)\n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "        return self.std_model.get_results(Y_test, Y_pred)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m]\n\u001b[1;32m      2\u001b[0m error_pred_3 \u001b[38;5;241m=\u001b[39m Error_Predictor(\u001b[38;5;241m0b00011\u001b[39m, hidden_layers\u001b[38;5;241m=\u001b[39mlayers, std_model\u001b[38;5;241m=\u001b[39mdropped_model_5)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43merror_pred_3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_5f_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_5f_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_5f_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_5f_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 10\u001b[0m, in \u001b[0;36mError_Predictor.train\u001b[0;34m(self, epochs, X_train, X_test, Y_train, Y_test, alpha)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs, X_train, X_test, Y_train, Y_test, alpha):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_test \u001b[38;5;241m=\u001b[39m Y_test\n",
      "Cell \u001b[0;32mIn[67], line 50\u001b[0m, in \u001b[0;36mDataPredictor.train\u001b[0;34m(self, epochs, X_train, X_test, alpha, loss_fn, Y_tr, Y_te)\u001b[0m\n\u001b[1;32m     48\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_train_new)\n\u001b[1;32m     49\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(Y_pred, Y_train)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_test \u001b[38;5;241m=\u001b[39m Y_test\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [64,64]\n",
    "error_pred_3 = Error_Predictor(0b00011, hidden_layers=layers, std_model=dropped_model_5).to(device)\n",
    "error_pred_3.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Y_pred_raw \u001b[38;5;241m=\u001b[39m error_pred_3\u001b[38;5;241m.\u001b[39mpredict(X_test_5f_device)\n\u001b[0;32m----> 2\u001b[0m results_1 \u001b[38;5;241m=\u001b[39m \u001b[43merror_pred_3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test_5f_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m error_pred_3\u001b[38;5;241m.\u001b[39mprint_results()\n\u001b[1;32m      5\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 24\u001b[0m, in \u001b[0;36mError_Predictor.get_results\u001b[0;34m(self, Y_test, Y_pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_pred\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Intro_ML_Project/alarmnetclass.py:57\u001b[0m, in \u001b[0;36mAlarmNet.get_results\u001b[0;34m(self, Y_test, Y_pred)\u001b[0m\n\u001b[1;32m     55\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_pred\n\u001b[1;32m     56\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m Y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 57\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mY_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     58\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(Y_test, Y_pred),\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision_score(Y_test, Y_pred),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report\u001b[39m\u001b[38;5;124m'\u001b[39m: classification_report(Y_test, Y_pred)\n\u001b[1;32m     65\u001b[0m }\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_results \u001b[38;5;241m=\u001b[39m results\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "Y_pred_raw = error_pred_3.predict(X_test_5f_device)\n",
    "results_1 = error_pred_3.get_results(Y_test_5f_device, Y_raw)\n",
    "error_pred_3.print_results()\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute_test_1 = X_test_5f.copy()\n",
    "\n",
    "\n",
    "imputer.fit(X_impute_test_1)\n",
    "X_impute_test_1[:, error_pred_3.predictor.output_cols] = np.nan\n",
    "X_impute_test_1 = imputer.transform(X_impute_test_1)\n",
    "X_impute_test_1_device = torch.tensor(X_impute_test_1).float().to(device)\n",
    "\n",
    "\n",
    "Y_pred_std = dropped_model_5.predict(X_impute_test_1_device)\n",
    "results_2 = dropped_model_5.get_results(Y_test_impute_device, Y_pred_std)\n",
    "dropped_model_5.print_results()\n",
    "\n",
    "AlarmNet.compare_results(results_1, results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Error Predictor with 2 errors\n",
    "-The predictor is much more likely to predict a false negative than the imputer, making this not the right choice for a fire alarm\n",
    "- Hopefully this changes in the case of the full ensemble\n",
    "- Compared to the imputer method, the predictor is better in all metrics except for recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleNet(AlarmNet):\n",
    "    def __init__(self,\n",
    "                 num_inputs,\n",
    "                 hidden_layers_std=[64,32],\n",
    "                 hidden_layers_pred = [64,64],\n",
    "                 activation=nn.Tanh,\n",
    "                 device='cuda'\n",
    "    ):\n",
    "        super().__init__(pass_through=True)\n",
    "        self.std_model = AlarmNet(num_inputs)\n",
    "        self.models = [self.std_model]\n",
    "        for i in range(1, 15):\n",
    "            error_model = Error_Predictor(\n",
    "                error_mode = i,\n",
    "                hidden_layers=hidden_layers_pred,\n",
    "                activation=nn.Tanh,\n",
    "                std_model=self.std_model\n",
    "            ).to(device)\n",
    "            self.models.append(error_model)\n",
    "        constant = ConstantPredictor(1)\n",
    "        self.models.append(constant)\n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha):\n",
    "        for model in self.models:\n",
    "            model.train(epochs, X_train, X_test, Y_train, Y_test, alpha)\n",
    "    def predict(self, X):\n",
    "        Y_pred = torch.zeros(X.shape[0], 1).to(X.device)\n",
    "        for idx, datapoint in enumerate(X):\n",
    "            error_mode = 0\n",
    "            \n",
    "            for i in range(0,5):\n",
    "                if datapoint[i] == np.nan:\n",
    "                    error_mode |= (1 << i)\n",
    "            print(f'Datapoint {idx}, Error Mode: {error_mode}')\n",
    "            error_mode >>= 1\n",
    "            Y_pred[idx] = self.models[error_mode].predict(datapoint)\n",
    "        return Y_pred\n",
    "    def eval(self, X, Y_test):\n",
    "        self.last_test = Y_test\n",
    "        self.Y_pred = self.predict(X)\n",
    "        self.last_results = self.get_results(Y_test, self.Y_pred)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleNet(X_train_5f.shape[1]).to(device)\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "\n",
    "ensemble.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensemble.eval(X_test_5f_device, Y_test_5f_device)\n",
    "ensemble.print_results()\n",
    "\n",
    "\n",
    "\n",
    "results_3 = ensemble.get_results()\n",
    "AlarmNet.compare_results(results_3, results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
