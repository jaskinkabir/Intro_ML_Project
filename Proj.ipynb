{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'smoke_detection_iot.csv'\n",
    "\n",
    "data = pd.read_csv(path).drop(['Unnamed: 0', 'UTC', 'CNT'], axis=1)\n",
    "Y_df = data['Fire Alarm']\n",
    "X_df = data.drop('Fire Alarm', axis=1)\n",
    "\n",
    "Y_test_raw = X_df.values\n",
    "Y_raw = Y_df.values\n",
    "\n",
    "X_train_raw, X_test_raw, Y_train_raw, Y_test_raw = train_test_split(Y_test_raw, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_raw = scaler.fit_transform(X_train_raw)\n",
    "X_test_raw = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6938216686248779\n",
      "Epoch 500 Loss: 0.0029248378705233335\n",
      "Epoch 1000 Loss: 0.0005927391466684639\n",
      "Epoch 1500 Loss: 0.0002855720813386142\n",
      "Epoch 2000 Loss: 0.00018974723934661597\n",
      "Epoch 2500 Loss: 0.00012954707199241966\n",
      "Accuracy: 0.9940124540954814\n",
      "Precision: 0.9936383928571428\n",
      "Recall: 0.9979822889810559\n",
      "F1: 0.9958056037134388\n",
      "Confusion_matrix:\n",
      "[[3548   57]\n",
      " [  18 8903]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      3605\n",
      "         1.0       0.99      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           0.99     12526\n",
      "   macro avg       0.99      0.99      0.99     12526\n",
      "weighted avg       0.99      0.99      0.99     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from alarmnetclass import AlarmNet\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "alpha = 1e-2\n",
    "epochs = 3000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "full_model = AlarmNet(\n",
    "    num_features=X_train_raw.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_raw_device = torch.tensor(X_train_raw).float().to(device)\n",
    "X_test_raw_device = torch.tensor(X_test_raw).float().to(device)\n",
    "Y_train_raw_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_raw_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "full_model.train(epochs, X_train_raw_device, X_test_raw_device, Y_train_raw_device, Y_test_raw_device, alpha)\n",
    "full_model.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "- Initially there are 15 features\n",
    "- 3 are unusable\n",
    "    - UTC Timestamp\n",
    "    - CNT\n",
    "    - Unnamed: 0\n",
    "- 12 features are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humidity[%]       0.399846\n",
      "Raw Ethanol       0.340652\n",
      "Pressure[hPa]     0.249797\n",
      "TVOC[ppb]         0.214743\n",
      "Temperature[C]    0.163902\n",
      "NC0.5             0.128118\n",
      "PM1.0             0.110552\n",
      "Raw H2            0.107007\n",
      "eCO2[ppm]         0.097006\n",
      "PM2.5             0.084916\n",
      "NC1.0             0.082828\n",
      "NC2.5             0.057707\n",
      "Name: Fire Alarm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "corr = np.abs(data.corr())\n",
    "ranking = corr['Fire Alarm'].sort_values(ascending=False)[1:]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: Index(['Humidity[%]', 'Raw Ethanol', 'Pressure[hPa]', 'TVOC[ppb]'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_drops = 8\n",
    "remaining_features = ranking.index[:-num_drops]\n",
    "\n",
    "\n",
    "X_df_dropped = data[remaining_features]\n",
    "print('Remaining features:', X_df_dropped.columns)\n",
    "X_train_dropped, X_test_dropped, Y_train_dropped, Y_test_dropped = train_test_split(X_df_dropped.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.transform(X_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7010210752487183\n",
      "Epoch 500 Loss: 0.01389069203287363\n",
      "Epoch 1000 Loss: 0.049671173095703125\n",
      "Epoch 1500 Loss: 0.046767473220825195\n",
      "Epoch 2000 Loss: 0.04530363902449608\n",
      "Epoch 2500 Loss: 0.0446198433637619\n",
      "Accuracy: 0.9726169567300016\n",
      "Precision: 0.9705946894886988\n",
      "Recall: 0.9915928707543997\n",
      "F1: 0.980981425006931\n",
      "Confusion_matrix:\n",
      "[[3337  268]\n",
      " [  75 8846]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95      3605\n",
      "         1.0       0.97      0.99      0.98      8921\n",
      "\n",
      "    accuracy                           0.97     12526\n",
      "   macro avg       0.97      0.96      0.97     12526\n",
      "weighted avg       0.97      0.97      0.97     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -2.1997865878683465 %\n",
      "precision: -2.3741839531991786 %\n",
      "recall: -0.644359032330994 %\n",
      "f1: -1.5111579412834586 %\n"
     ]
    }
   ],
   "source": [
    "dropped_model = AlarmNet(\n",
    "    num_features=X_train_dropped.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_dropped_device = torch.tensor(X_train_dropped).float().to(device)\n",
    "X_test_dropped_device = torch.tensor(X_test_dropped).float().to(device)\n",
    "Y_train_dropped_device = torch.tensor(Y_train_dropped).float().view(-1, 1).to(device)\n",
    "Y_test_dropped_device = torch.tensor(Y_test_dropped).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model.train(epochs, X_train_dropped_device, X_test_dropped_device, Y_train_dropped_device, Y_test_dropped_device, alpha)\n",
    "dropped_model.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model.get_results(), full_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Results\n",
    "- We can remove the bottom 8 features and have a model that only loses 0.1% precision, and even less for every other metric\n",
    "- A 4 feature model is almost perfect\n",
    "    - These features are:\n",
    "        - Humidity\n",
    "        - Raw Ethanol\n",
    "        - Pressure\n",
    "        - TVOC\n",
    "\n",
    "# Error Handling\n",
    "- The 12 initial features came from 4 sensors\n",
    "    - Temp/Humidity\n",
    "    - Pressure\n",
    "    - Volatile Organic Compounds (CO2, Ethanol, H2, TVOC)\n",
    "    - Particulate Matter (PM1, PM2.5, NC0.5, NC1, NC2.5)\n",
    "- 3 of these sensors are redundant, with the exception being the PM sensor\n",
    "    - This means that the features related to the PM sensor are twice as likely to be missing\n",
    "- We can simulate a real world scenario by introducing error according to this distribution\n",
    "- Note that the Particulate Matter sensor is not included in the 4-feature model.\n",
    "    - To add redundancy to our model, we can add back the most correlated feature from the PM sensor\n",
    "    - This feature is PM0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add back the most correlated PM feature, so that all 4 sensors are used\n",
    "# PM0.5 is the most correlated PM feature, with index 5\n",
    "remaining_features_2 = list(remaining_features)\n",
    "remaining_features_2.append(ranking.index[5])\n",
    "X_5f = data[remaining_features_2]\n",
    "X_train_5f, X_test_5f, Y_train_5f, Y_test_5f = train_test_split(X_5f.values, Y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_5f = scaler.fit_transform(X_train_5f)\n",
    "X_test_5f = scaler.transform(X_test_5f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6826237440109253\n",
      "Epoch 500 Loss: 0.011827047914266586\n",
      "Epoch 1000 Loss: 0.054410360753536224\n",
      "Epoch 1500 Loss: 0.05195501819252968\n",
      "Epoch 2000 Loss: 0.050904519855976105\n",
      "Epoch 2500 Loss: 0.0504881776869297\n",
      "Accuracy: 0.999041992655277\n",
      "Precision: 0.9987683350128765\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9993278064082456\n",
      "Confusion_matrix:\n",
      "[[3594   11]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 0.5034361515103059 %\n",
      "precision: 0.5136268317584943 %\n",
      "recall: 0.19058295964125666 %\n",
      "f1: 0.35245718894445044 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dropped_model_5 = AlarmNet(\n",
    "    num_features=X_train_5f.shape[1],  # Update to match the new input dimensions\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "epochs = 3000\n",
    "alpha = 1e-2\n",
    "\n",
    "X_train_5f_device = torch.tensor(X_train_5f).float().to(device)\n",
    "X_test_5f_device = torch.tensor(X_test_5f).float().to(device)\n",
    "Y_train_5f_device = torch.tensor(Y_train_raw).float().view(-1, 1).to(device)\n",
    "Y_test_5f_device = torch.tensor(Y_test_raw).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model_5.train(epochs, X_train_5f_device, X_test_5f_device, Y_train_5f_device, Y_test_5f_device, alpha)\n",
    "\n",
    "dropped_model_5_results = dropped_model_5.get_results()\n",
    "dropped_model_5.print_results()\n",
    "\n",
    "AlarmNet.compare_results(dropped_model_5_results, full_model.get_results())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Introduce sensor errors\n",
    "\n",
    "VOC_features = [\n",
    "    'TVOC[ppb]',\n",
    "    'eCO2[ppm]',\n",
    "    'Raw H2',\n",
    "    'Raw Ethanol'\n",
    "]\n",
    "\n",
    "PM_features = [\n",
    "    'PM1.0',\n",
    "    'PM2.5',\n",
    "    'NC0.5',\n",
    "    'NC1.0',\n",
    "    'NC2.5'\n",
    "]\n",
    "\n",
    "th_features = [\n",
    "    'Temperature[C]',\n",
    "    'Humidity[%]'\n",
    "]\n",
    "pressure_features = [\n",
    "    'Pressure[hPa]'\n",
    "]\n",
    "\n",
    "# For each measurement, each sensor has this chance of introducing an error\n",
    "error_chance = 0.2\n",
    "\n",
    "# The PM sensor is twice as likely to fail due to lack of redundancy\n",
    "chances = [error_chance, error_chance*2, error_chance, error_chance]\n",
    "sensors = [VOC_features, PM_features, th_features, pressure_features]\n",
    "\n",
    "error_mask = np.ones(X_5f.shape)\n",
    "\n",
    "# for i, row in error_mask:\n",
    "#     errored_features = []\n",
    "#     for j, sensor in enumerate(sensors):\n",
    "#         sensor_error = random.random() < chances[j]\n",
    "#         if sensor_error:\n",
    "#             errored_features.extend(sensor)\n",
    "#     errored_features = [feature for feature in errored_features if feature in X_error.columns]\n",
    "#     if errored_features:\n",
    "#         for feature in errored_features:\n",
    "#             error_mask[i][X_error.columns.get_loc(feature)] = np.nan\n",
    "#         print(i, error_mask[i])\n",
    "\n",
    "X_error_np = X_5f.values.copy()\n",
    "for i, datapoint in enumerate(X_5f.values):\n",
    "    errored_features = []\n",
    "    for j, sensor in enumerate(sensors):\n",
    "        sensor_error = random.random() < chances[j]\n",
    "        if sensor_error:\n",
    "            errored_features.extend(sensor)\n",
    "    errored_features = [feature for feature in errored_features if feature in X_5f.columns]\n",
    "    if errored_features:\n",
    "        for feature in errored_features:\n",
    "            X_error_np[i][X_5f.columns.get_loc(feature)] = np.nan\n",
    "        # print(i, X_error_np[i])\n",
    "\n",
    "X_train_error, X_test_error, Y_train_error, Y_test_error = train_test_split(X_error_np, Y_raw, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "- Replace each errored value with the mean of that feature from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_5f.values)\n",
    "imputer.fit(X_train_error)\n",
    "X_impute_train = imputer.transform(X_train_error)\n",
    "X_impute_test = imputer.transform(X_test_error)\n",
    "\n",
    "X_impute_train = scaler.fit_transform(X_impute_train)\n",
    "X_impute_test = scaler.transform(X_impute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6883925795555115\n",
      "Epoch 500 Loss: 0.17090661823749542\n",
      "Epoch 1000 Loss: 0.13784246146678925\n",
      "Epoch 1500 Loss: 0.1114770919084549\n",
      "Epoch 2000 Loss: 0.07624808698892593\n",
      "Epoch 2500 Loss: 0.05974220111966133\n",
      "Epoch 3000 Loss: 0.05209113284945488\n",
      "Epoch 3500 Loss: 0.04784805327653885\n",
      "Epoch 4000 Loss: 0.0450618751347065\n",
      "Epoch 4500 Loss: 0.043051548302173615\n",
      "Epoch 5000 Loss: 0.041324738413095474\n",
      "Epoch 5500 Loss: 0.03987447917461395\n",
      "Epoch 6000 Loss: 0.038674090057611465\n",
      "Epoch 6500 Loss: 0.03717140853404999\n",
      "Epoch 7000 Loss: 0.03625910356640816\n",
      "Epoch 7500 Loss: 0.035581715404987335\n",
      "Epoch 8000 Loss: 0.035002559423446655\n",
      "Epoch 8500 Loss: 0.03459536284208298\n",
      "Epoch 9000 Loss: 0.03415282443165779\n",
      "Epoch 9500 Loss: 0.03381981700658798\n",
      "Epoch 10000 Loss: 0.033510755747556686\n",
      "Epoch 10500 Loss: 0.03325588256120682\n",
      "Epoch 11000 Loss: 0.033162716776132584\n",
      "Epoch 11500 Loss: 0.03287045657634735\n",
      "Epoch 12000 Loss: 0.03272054344415665\n",
      "Epoch 12500 Loss: 0.032776907086372375\n",
      "Epoch 13000 Loss: 0.032554302364587784\n",
      "Epoch 13500 Loss: 0.03231680765748024\n",
      "Epoch 14000 Loss: 0.03222506493330002\n",
      "Epoch 14500 Loss: 0.032248012721538544\n",
      "Epoch 15000 Loss: 0.03202803060412407\n",
      "Epoch 15500 Loss: 0.03196895867586136\n",
      "Accuracy: 0.9863483953376976\n",
      "Precision: 0.9871937639198218\n",
      "Recall: 0.9937226768299517\n",
      "F1: 0.9904474610356964\n",
      "Confusion_matrix:\n",
      "[[3490  115]\n",
      " [  56 8865]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98      3605\n",
      "         1.0       0.99      0.99      0.99      8921\n",
      "\n",
      "    accuracy                           0.99     12526\n",
      "   macro avg       0.99      0.98      0.98     12526\n",
      "weighted avg       0.99      0.99      0.99     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: -1.2869283690813464 %\n",
      "precision: -1.1724720633460946 %\n",
      "recall: -0.62041737168641 %\n",
      "f1: -0.8965993373604269 %\n"
     ]
    }
   ],
   "source": [
    "imputed_model = AlarmNet(\n",
    "    num_features=X_impute_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[128, 256, 128]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_impute_train_device = torch.tensor(X_impute_train).float().to(device)\n",
    "X_impute_test_device = torch.tensor(X_impute_test).float().to(device)\n",
    "Y_train_impute_device = torch.tensor(Y_train_error).float().view(-1, 1).to(device)\n",
    "Y_test_impute_device = torch.tensor(Y_test_error).float().view(-1, 1).to(device)\n",
    "\n",
    "imputed_model.train(\n",
    "    epochs= 16000,\n",
    "    X_train = X_impute_train_device,\n",
    "    X_test = X_impute_test_device,\n",
    "    Y_train = Y_train_impute_device,\n",
    "    Y_test = Y_test_impute_device,\n",
    "    alpha= 1e-4,\n",
    "    loss_fn = nn.BCELoss(),\n",
    "    optimizer = torch.optim.Adam\n",
    ")\n",
    "imputed_model.print_results()\n",
    "AlarmNet.compare_results(imputed_model.get_results(), dropped_model_5.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Modes\n",
    "- Current features:\n",
    "    - Humidity\n",
    "    - Raw Ethanol\n",
    "    - Pressure\n",
    "    - TVOC\n",
    "    - NC0.5\n",
    "- Sensors:\n",
    "    - Humidity\n",
    "    - Pressure\n",
    "    - Raw Ethanol/TVOC\n",
    "    - NC0.5\n",
    "- The model should be able to handle missing data in the case where at most 3 sensors have failed, because 4 failed sensors means no data\n",
    "    - 1 failed sensor = 4c1 = 4\n",
    "    - 2 failed sensors = 4c2 = 6\n",
    "    - 3 failed sensors = 4c3 = 4\n",
    "    - Total = 14\n",
    "## Ensemble Training\n",
    "- We can train 14 models that can predict the missing data for each error mode\n",
    "- In the case of error, we select the model that corresponds to the error mode and use it to predict the missing data\n",
    "- Then use the main model to predict the target\n",
    "### Indexing Ensemble\n",
    "- Columns should be rearranged according to sensors\n",
    "    - Humidity, Pressure, NC0.5, Ethanol, TVOC, \n",
    "- The error mode can be represented as a 4-bit value\n",
    "    - 0b0000 = No error\n",
    "    - 0b0001 = Ethanol/TVOC Error\n",
    "    - 0b0010 = NC0.5 Error\n",
    "    - 0b0100 = Pressure error\n",
    "    - 0b1000 = Humidity error\n",
    "- A 5-bit value can represent which features are missing\n",
    "    - 0b00000 = No error\n",
    "    - 0b00011 = Ethanol/TVOC Error\n",
    "    - 0b00100 = NC0.5 Error\n",
    "    - 0b01000 = Pressure error\n",
    "    - 0b10000 = Humidity error\n",
    "- We can convert from the 5-bit value to the 4-bit value with a simple shift right operation\n",
    "\n",
    "### Model Table\n",
    "- Store the models with an array\n",
    "- The index of the model is the error mode\n",
    "- Model 15 will always predict 1, because if all sensors have failed the worst should be assumed for safety\n",
    "- Model 0 will be the standard model trained on a full dataset\n",
    "- The rest of the arrays will be trained on the data with the corresponding error mode\n",
    "### New Model Type\n",
    "- A new model class will be created that will predict the missing values, construct the repaired dataset, call the standard model, and return the result\n",
    "### Ensemble Class\n",
    "- This new class will hold the model table and the standard model\n",
    "- It will be responsible for constructing the model address, calling the correct model, and returning the result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
