{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'smoke_detection_iot.csv'\n",
    "\n",
    "data = pd.read_csv(path).drop(['Unnamed: 0', 'UTC', 'CNT'], axis=1)\n",
    "Y_df = data['Fire Alarm']\n",
    "X_df = data.drop('Fire Alarm', axis=1)\n",
    "\n",
    "X = X_df.values\n",
    "Y = Y_df.values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlarmNet(nn.Module):\n",
    "\n",
    "    @classmethod\n",
    "    def compare_results(cls, results1, results2):\n",
    "        print('Comparing results:')\n",
    "        comparisons = {\n",
    "            'accuracy': 100*(results1['accuracy'] - results2['accuracy'])/results1['accuracy'],\n",
    "            'precision': 100*(results1['precision'] - results2['precision'])/results1['precision'],\n",
    "            'recall': 100*(results1['recall'] - results2['recall'])/results1['recall'],\n",
    "            'f1': 100*(results1['f1'] - results2['f1'])/results1['f1']\n",
    "        }\n",
    "        for key, value in comparisons.items():\n",
    "            print(f'{key}: {value} %')\n",
    "    def __init__(self, num_features, activation=nn.ReLU, hidden_layers = [64, 32, 16],):\n",
    "        super(AlarmNet, self).__init__()\n",
    "        self.stack_list = [nn.Linear(num_features, hidden_layers[0]), activation()]\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.stack_list.extend([nn.Linear(hidden_layers[i-1], hidden_layers[i]), activation()])  # Use extend instead of assignment\n",
    "        \n",
    "        self.stack_list.extend([nn.Linear(hidden_layers[-1], 1), nn.Sigmoid()])  # Use extend instead of assignment\n",
    "        self.stack = nn.Sequential(*self.stack_list)\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "    def predict(self, x):\n",
    "        return self.forward(x).round()\n",
    "    def train(self, epochs, X_train, X_test, Y_train, Y_test, alpha, loss_fn=nn.BCELoss()):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=alpha)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            Y_pred = self.forward(X_train)\n",
    "            loss = loss_fn(Y_pred, Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 500 == 0:\n",
    "                print(f'Epoch {epoch} Loss: {loss.item()}')\n",
    "        Y_pred = self.predict(X_test)\n",
    "        self.last_pred = Y_pred\n",
    "        self.last_test = Y_test\n",
    "        return [Y_test,Y_pred]\n",
    "    \n",
    "    def get_results(self, Y_test=None, Y_pred=None):\n",
    "        if Y_test is None:\n",
    "            Y_test = self.last_test\n",
    "        if Y_pred is None:\n",
    "            Y_pred = self.last_pred\n",
    "        Y_test = Y_test.cpu().detach().numpy()\n",
    "        Y_pred = Y_pred.cpu().detach().numpy()\n",
    "        results = {\n",
    "            'accuracy': accuracy_score(Y_test, Y_pred),\n",
    "            'precision': precision_score(Y_test, Y_pred),\n",
    "            'recall': recall_score(Y_test, Y_pred),\n",
    "            'f1': f1_score(Y_test, Y_pred),\n",
    "            'confusion_matrix': confusion_matrix(Y_test, Y_pred),\n",
    "            'classification_report': classification_report(Y_test, Y_pred)\n",
    "        }\n",
    "        self.last_results = results\n",
    "        return results\n",
    "    def print_results(self, results=None):\n",
    "        if results is None:\n",
    "            try: \n",
    "                results = self.last_results\n",
    "            except:\n",
    "                results = self.get_results()\n",
    "        for key, value in results.items():\n",
    "            if key != 'confusion_matrix':\n",
    "                print(f'{key.capitalize()}: {value}')\n",
    "            else:\n",
    "                print(f'{key.capitalize()}:\\n{value}')\n",
    "    \n",
    "    def train_and_print(self, epochs, X_train, X_test, Y_train, Y_test, alpha):\n",
    "        Y_pred = self.train(epochs, X_train, X_test, Y_train, Y_test, alpha).cpu().detach().numpy().round().astype(int)\n",
    "        self.print_results(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6930141448974609\n",
      "Epoch 500 Loss: 0.003083854680880904\n",
      "Epoch 1000 Loss: 0.0006931198295205832\n",
      "Epoch 1500 Loss: 0.0003832397342193872\n",
      "Epoch 2000 Loss: 0.004771542735397816\n",
      "Epoch 2500 Loss: 0.002212930005043745\n",
      "Accuracy: 0.9999201660546064\n",
      "Precision: 1.0\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9999439493301945\n",
      "Confusion_matrix:\n",
      "[[3605    0]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "alpha = 1e-2\n",
    "epochs = 3000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = AlarmNet(\n",
    "    num_features=X_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_device = torch.tensor(X_train).float().to(device)\n",
    "X_test_device = torch.tensor(X_test).float().to(device)\n",
    "Y_train_device = torch.tensor(Y_train).float().view(-1, 1).to(device)\n",
    "Y_test_device = torch.tensor(Y_test).float().view(-1, 1).to(device)\n",
    "model.train(epochs, X_train_device, X_test_device, Y_train_device, Y_test_device, alpha)\n",
    "model.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "- Initially there are 15 features\n",
    "- 3 are unusable\n",
    "    - UTC Timestamp\n",
    "    - CNT\n",
    "    - Unnamed: 0\n",
    "- 12 features are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humidity[%]       0.399846\n",
      "Raw Ethanol       0.340652\n",
      "Pressure[hPa]     0.249797\n",
      "TVOC[ppb]         0.214743\n",
      "Temperature[C]    0.163902\n",
      "NC0.5             0.128118\n",
      "PM1.0             0.110552\n",
      "Raw H2            0.107007\n",
      "eCO2[ppm]         0.097006\n",
      "PM2.5             0.084916\n",
      "NC1.0             0.082828\n",
      "NC2.5             0.057707\n",
      "Name: Fire Alarm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "corr = np.abs(data.corr())\n",
    "ranking = corr['Fire Alarm'].sort_values(ascending=False)[1:]\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features: Index(['Humidity[%]', 'Raw Ethanol', 'Pressure[hPa]', 'TVOC[ppb]'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_drops = 8\n",
    "remaining_features = ranking.index[:-num_drops]\n",
    "\n",
    "\n",
    "X_df_dropped = data[remaining_features]\n",
    "print('Remaining features:', X_df_dropped.columns)\n",
    "X_train_dropped, X_test_dropped, Y_train_dropped, Y_test_dropped = train_test_split(X_df_dropped.values, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_dropped = scaler.fit_transform(X_train_dropped)\n",
    "X_test_dropped = scaler.transform(X_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7067186236381531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 0.056268975138664246\n",
      "Epoch 1000 Loss: 0.048675552010536194\n",
      "Epoch 1500 Loss: 0.07611647993326187\n",
      "Epoch 2000 Loss: 0.05350978299975395\n",
      "Epoch 2500 Loss: 0.05019477382302284\n",
      "Accuracy: 0.999041992655277\n",
      "Precision: 0.9987683350128765\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9993278064082456\n",
      "Confusion_matrix:\n",
      "[[3594   11]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_model = AlarmNet(\n",
    "    num_features=X_train_dropped.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_train_dropped_device = torch.tensor(X_train_dropped).float().to(device)\n",
    "X_test_dropped_device = torch.tensor(X_test_dropped).float().to(device)\n",
    "Y_train_dropped_device = torch.tensor(Y_train_dropped).float().view(-1, 1).to(device)\n",
    "Y_test_dropped_device = torch.tensor(Y_test_dropped).float().view(-1, 1).to(device)\n",
    "\n",
    "dropped_model.train(epochs, X_train_dropped_device, X_test_dropped_device, Y_train_dropped_device, Y_test_dropped_device, alpha)\n",
    "dropped_model.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing results:\n",
      "accuracy: -0.08790155026370366 %\n",
      "precision: -0.12331838565021994 %\n",
      "recall: 0.0 %\n",
      "f1: -0.06165573678605171 %\n"
     ]
    }
   ],
   "source": [
    "AlarmNet.compare_results(dropped_model.get_results(), model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Results\n",
    "- We can remove the bottom 8 features and have a model that only loses 0.1% precision, and even less for every other metric\n",
    "- A 4 feature model is almost perfect\n",
    "\n",
    "# Error Handling\n",
    "- The 12 initial features came from 4 sensors\n",
    "    - Temp/Humidity\n",
    "    - Pressure\n",
    "    - Volatile Organic Compounds (CO2, Ethanol, H2, TVOC)\n",
    "    - Particulate Matter (PM1, PM2.5, NC0.5, NC1, NC2.5)\n",
    "- 3 of these sensors are redundant, with the exception being the PM sensor\n",
    "    - This means that the features related to the PM sensor are twice as likely to be missing\n",
    "- We can simulate a real world scenario by introducing error according to this distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Add back the most correlated PM feature, so that all 4 sensors are used\n",
    "# PM0.5 is the most correlated PM feature, with index 5\n",
    "remaining_features_2 = list(remaining_features)\n",
    "remaining_features_2.append(ranking.index[5])\n",
    "X_error = data[remaining_features_2]\n",
    "# For each measurement, each sensor has this chance of introducing an error\n",
    "error_chance = 0.2\n",
    "\n",
    "# Introduce sensor errors\n",
    "\n",
    "VOC_features = [\n",
    "    'TVOC[ppb]',\n",
    "    'eCO2[ppm]',\n",
    "    'Raw H2',\n",
    "    'Raw Ethanol'\n",
    "]\n",
    "\n",
    "PM_features = [\n",
    "    'PM1.0',\n",
    "    'PM2.5',\n",
    "    'NC0.5',\n",
    "    'NC1.0',\n",
    "    'NC2.5'\n",
    "]\n",
    "\n",
    "th_features = [\n",
    "    'Temperature[C]',\n",
    "    'Humidity[%]'\n",
    "]\n",
    "pressure_features = [\n",
    "    'Pressure[hPa]'\n",
    "]\n",
    "\n",
    "# The PM sensor is twice as likely to fail due to lack of redundancy\n",
    "chances = [error_chance, error_chance*2, error_chance, error_chance]\n",
    "sensors = [VOC_features, PM_features, th_features, pressure_features]\n",
    "for datapoint in X_error.values:\n",
    "    errored_features = []\n",
    "    for i, sensor in enumerate(sensors):\n",
    "        sensor_error = random.random() < chances[i]\n",
    "        if sensor_error:\n",
    "            errored_features.extend(sensor)\n",
    "    errored_features = [feature for feature in errored_features if feature in X_error.columns]\n",
    "    for feature in errored_features:\n",
    "        datapoint[X_error.columns.get_loc(feature)] = np.nan\n",
    "\n",
    "X_train_error, X_test_error, Y_train_error, Y_test_error = train_test_split(X_error, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "- Replace each errored value with the mean of that feature from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute_train = imputer.fit_transform(X_train_error)\n",
    "X_impute_test = imputer.transform(X_test_error)\n",
    "\n",
    "X_impute_train = scaler.fit_transform(X_impute_train)\n",
    "X_impute_test = scaler.transform(X_impute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.2368442863225937\n",
      "Epoch 500 Loss: 0.003682525362819433\n",
      "Epoch 1000 Loss: 0.07692201435565948\n",
      "Epoch 1500 Loss: 0.0008170432993210852\n",
      "Epoch 2000 Loss: 0.0004960561054758728\n",
      "Epoch 2500 Loss: 0.0003281506069470197\n",
      "Accuracy: 0.9999201660546064\n",
      "Precision: 1.0\n",
      "Recall: 0.999887904943392\n",
      "F1: 0.9999439493301945\n",
      "Confusion_matrix:\n",
      "[[3605    0]\n",
      " [   1 8920]]\n",
      "Classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3605\n",
      "         1.0       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Comparing results:\n",
      "accuracy: 0.08782435129740421 %\n",
      "precision: 0.12316649871234597 %\n",
      "recall: 0.0 %\n",
      "f1: 0.061617745910819435 %\n"
     ]
    }
   ],
   "source": [
    "imputed_model = AlarmNet(\n",
    "    num_features=X_impute_train.shape[1],\n",
    "    activation = nn.ReLU,\n",
    "    hidden_layers=[64, 32]\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "X_impute_train_device = torch.tensor(X_impute_train).float().to(device)\n",
    "X_impute_test_device = torch.tensor(X_impute_test).float().to(device)\n",
    "Y_train_impute_device = torch.tensor(Y_train_error).float().view(-1, 1).to(device)\n",
    "Y_test_impute_device = torch.tensor(Y_test_error).float().view(-1, 1).to(device)\n",
    "\n",
    "imputed_model.train(\n",
    "    epochs,\n",
    "    X_impute_train_device,\n",
    "    X_impute_test_device,\n",
    "    Y_train_impute_device,\n",
    "    Y_test_impute_device,\n",
    "    alpha,\n",
    "    loss_fn = nn.MSELoss()\n",
    ")\n",
    "imputed_model.print_results()\n",
    "AlarmNet.compare_results(imputed_model.get_results(), dropped_model.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Modes\n",
    "- Current features:\n",
    "    - Humidity\n",
    "    - Raw Ethanol\n",
    "    - Pressure\n",
    "    - TVOC\n",
    "    - NC0.5\n",
    "- Sensors:\n",
    "    - Humidity\n",
    "    - Pressure\n",
    "    - Raw Ethanol/TVOC\n",
    "    - NC0.5\n",
    "- The model should be able to handle missing data in the case where at most 3 sensors have failed, because 4 failed sensors means no data\n",
    "    - 1 failed sensor = 4c1 = 4\n",
    "    - 2 failed sensors = 4c2 = 6\n",
    "    - 3 failed sensors = 4c3 = 4\n",
    "    - Total = 14\n",
    "## Ensemble Training\n",
    "- We can train 14 models that can predict the missing data for each error mode\n",
    "- In the case of error, we select the model that corresponds to the error mode and use it to predict the missing data\n",
    "- Then use the main model to predict the target\n",
    "### Indexing Ensemble\n",
    "- Columns should be rearranged according to sensors\n",
    "    - Humidity, Pressure, NC0.5, Ethanol, TVOC, \n",
    "- The error mode can be represented as a 4-bit value\n",
    "    - 0b0000 = No error\n",
    "    - 0b0001 = Ethanol/TVOC Error\n",
    "    - 0b0010 = NC0.5 Error\n",
    "    - 0b0100 = Pressure error\n",
    "    - 0b1000 = Humidity error\n",
    "- A 5-bit value can represent which features are missing\n",
    "    - 0b00000 = No error\n",
    "    - 0b00011 = Ethanol/TVOC Error\n",
    "    - 0b00100 = NC0.5 Error\n",
    "    - 0b01000 = Pressure error\n",
    "    - 0b10000 = Humidity error\n",
    "- We can convert from the 5-bit value to the 4-bit value with a simple shift right operation\n",
    "\n",
    "### Model Table\n",
    "- Store the models with an array\n",
    "- The index of the model is the error mode\n",
    "- Model 15 will always predict 1, because if all sensors have failed the worst should be assumed for safety\n",
    "- Model 0 will be the standard model trained on a full dataset\n",
    "- The rest of the arrays will be trained on the data with the corresponding error mode\n",
    "### New Model Type\n",
    "- A new model class will be created that will predict the missing values, construct the repaired dataset, call the standard model, and return the result\n",
    "### Ensemble Class\n",
    "- This new class will hold the model table and the standard model\n",
    "- It will be responsible for constructing the model address, calling the correct model, and returning the result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
